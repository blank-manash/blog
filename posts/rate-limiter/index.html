<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Rate Limiter | Emacsome</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../rss.xml">
<link rel="canonical" href="https://blank-manash.github.io/blog/posts/rate-limiter/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Manash Baul">
<link rel="prev" href="../am-i-back/" title="Am I back?" type="text/html">
<meta property="og:site_name" content="Emacsome">
<meta property="og:title" content="Rate Limiter">
<meta property="og:url" content="https://blank-manash.github.io/blog/posts/rate-limiter/">
<meta property="og:description" content="Rate Limiter: The Why?


Rate Limiters are fundamental tools in order to facilitate security measures against DDoS attacks. It also helps in managing cost, regulate QPS and render deterministic expect">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-06-19T01:08:08+05:30">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Header and menu bar -->
<div class="container">
      <header class="blog-header py-3"><div class="row nbb-header align-items-center">
          <div class="col-md-3 col-xs-2 col-sm-2" style="width: auto;">
            <button class="navbar-toggler navbar-light bg-light nbb-navbar-toggler" type="button" data-toggle="collapse" data-target=".bs-nav-collapsible" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse bs-nav-collapsible bootblog4-search-form-holder">
                
            </div>
        </div>
          <div class="col-md-6 col-xs-10 col-sm-10 bootblog4-brand" style="width: auto;">
            <a class="navbar-brand blog-header-logo text-dark" href="../../">

            <span id="blog-title">Emacsome</span>
        </a>
          </div>
            <div class="col-md-3 justify-content-end align-items-center bs-nav-collapsible collapse flex-collapse bootblog4-right-nav">
            <nav class="navbar navbar-light bg-white"><ul class="navbar-nav bootblog4-right-nav">
<li class="nav-item">
    <a href="index.org" id="sourcelink" class="nav-link">Source</a>
    </li>


                    
            </ul></nav>
</div>
    </div>
</header><nav class="navbar navbar-expand-md navbar-light bg-white static-top"><div class="collapse navbar-collapse bs-nav-collapsible" id="bs-navbar">
            <ul class="navbar-nav nav-fill d-flex w-100">
<li class="nav-item">
<a href="../../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../../categories/" class="nav-link">Tags</a>

                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
</nav>
</div>

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Rate Limiter</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Manash Baul
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-06-19T01:08:08+05:30" itemprop="datePublished" title="2023-06-19 01:08">2023-06-19 01:08</time></a>
            </p>
            
        <p class="sourceline"><a href="index.org" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div id="outline-container-orgb6250a0" class="outline-2">
<h2 id="orgb6250a0">Rate Limiter: The Why?</h2>
<div class="outline-text-2" id="text-orgb6250a0">
<p>
Rate Limiters are fundamental tools in order to facilitate security measures against DDoS attacks. It also helps in managing cost, regulate QPS and render deterministic expections on the usage of our system. Almost all the services you know today have a Rate Limiter Service in place, which is also offered within your Cloud Subscription if you are hosting behind a Cloud Server.
</p>
</div>
</div>

<div id="outline-container-org40e3a83" class="outline-2">
<h2 id="org40e3a83">Rate Limiter: The How?</h2>
<div class="outline-text-2" id="text-org40e3a83">
<p>
Sure it seems simple enough to implement a Rate Limiting, with the requirements as simple as
</p>

<ul class="org-ul">
<li>Only an <code>x</code> number of requests are allowed from a host / IP / user per minute.</li>
</ul>
<p>
But as always, there are some caveats, and this blog is about that caveats. To being with, let's look at how we can implement such a service. We are assuming the rate limiter service will be included as an middleware with the API Gateway which redirects requests to the web server.
</p>
</div>

<div id="outline-container-org9b3c284" class="outline-3">
<h3 id="org9b3c284">Token Buckets</h3>
<div class="outline-text-3" id="text-org9b3c284">
<p>
Imagine we have a bucket, and we have it filled with some coins. Each request to pass through, requires 1 coin from it's bucket. If the bucket is empty, we drop the request. We also add a constant number of coins every second.
</p>

<p>
Here is a simple implementation. We used id as the identifier on how we are limiting the requests (example: IP)
</p>

<div class="highlight"><pre><span></span><span class="kt">bool</span><span class="w"> </span><span class="nf">passRequest</span><span class="p">(</span><span class="n">Request</span><span class="w"> </span><span class="n">request</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">request</span><span class="p">.</span><span class="n">id</span><span class="p">;</span>
<span class="w">  </span><span class="n">Bucket</span><span class="w"> </span><span class="n">bucket</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buckets</span><span class="p">[</span><span class="n">id</span><span class="p">];</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="o">!</span><span class="n">bucket</span><span class="p">.</span><span class="n">isEmpty</span><span class="p">();</span>
<span class="p">}</span>
</pre></div>

<p>
Although being simple and effective, the idea has a major flaw. It's is highly <b>resource intensive</b> as we would need a to create a bucket for every <code>id</code> and constantly refill all of the buckets in parallel. Due to such constraints it is an infeasible approach for a large scale system.
</p>
</div>
</div>

<div id="outline-container-org9c17ced" class="outline-3">
<h3 id="org9c17ced">Leaky Buckets</h3>
<div class="outline-text-3" id="text-org9c17ced">
<p>
The idea is same, however instead of refilling the bucket every second, we replace the entire bucket with a queue. The queue has a fixed capacity, and for every request that comes in, we check if the queue is in capacity. If it is, we drop the request.
</p>

<p>
This is a much better approach then the previous one as we don't have to constanty fill the bucket. And the outflow rate is the number of request processed per second. Do consider that this algorithm has a fixed rate of processing the request. And a sudden burst of traffic could cause the new requests to stall.
</p>
</div>
</div>

<div id="outline-container-orgb0a7eb6" class="outline-3">
<h3 id="orgb0a7eb6">Sliding Window Log Algorithm</h3>
<div class="outline-text-3" id="text-orgb0a7eb6">
<p>
This is the first approach that came to me when I first looked at the problem statement. The idea is same as before, to create a queue, but of timestamps.
</p>

<p>
For every request that comes, we do the following operation
</p>

<ul class="org-ul">
<li>Append the timestamp of the request to the queue.</li>
<li>Delete obsolete timestamps from queue.</li>
</ul>
<p>
Obsolete Timestamps: <i>Timestamp with time less than current start interval</i>
Typically that would mean if we are limiting by 1 min, then all the timestamps less than 1 min of current request would be removed from the queue.
</p>

<p>
This is a deterministic algorithm will accurate results. This doesn't impose a fixed rate of request consumption, as requests are served as they come. However storing timestamps for all the requests can be memory intensive, especially when scaled to a large number of users.
</p>
</div>
</div>

<div id="outline-container-org5138641" class="outline-3">
<h3 id="org5138641">Sliding Window Count Algorithm</h3>
<div class="outline-text-3" id="text-org5138641">
<p>
This is tweak on the above algorithm, with making it probabilistic but with very low probablity of error, and much simpler implemention.
We take a assumption that the rate of request is uniform over a window. And we keep a count only for the total number of requests recieved for the current window, and previous window. That's only two variables for each user.
</p>

<p>
Now the trick, we count the total number of request of an interval as <code>x * a + y * b</code>.
</p>
<ul class="org-ul">
<li>
<code>x</code>: Percentage of overlap of the last window.</li>
<li>
<code>a</code>: Number of requests recieved in the last window.</li>
<li>
<code>y</code>: Percentage of overlap of the current window.</li>
<li>
<code>b</code>: Number of requests recieved in the current window.</li>
</ul>
<p>
If you look at it, you would recognize it as a running average of the number of requests received. And this works very nicely for real world usecase. According to experiments, it has a 0.003% of requests wrongly allowed done over 400 million requests. (Cloudfare)
</p>
</div>
</div>
</div>

<div id="outline-container-orgb123308" class="outline-2">
<h2 id="orgb123308">Rate Limiter: The Caveats</h2>
<div class="outline-text-2" id="text-orgb123308">
</div>
<div id="outline-container-orgaec29ce" class="outline-3">
<h3 id="orgaec29ce">Synchronization</h3>
<div class="outline-text-3" id="text-orgaec29ce">
<p>
We could have too many requests for one rate limiter server to handle, for which we would need add multiple rate-limiter servers to filter requests. This would add the problem of data synchronization. Every request can go to random rate limiter which will make it diffcult to maintain the count of recieved request. One solution is to introduce sticky sessions where clients are redirected to a specific server for every server, but is easily isn't the best solution available.
</p>

<p>
The better approach is to use a cache or a database where the servers can connect to store client information. With this way information is decoupled with processing, allowing them to integrate independently.
</p>
</div>
</div>

<div id="outline-container-orgcd9b8a6" class="outline-3">
<h3 id="orgcd9b8a6">Race Conditions</h3>
<div class="outline-text-3" id="text-orgcd9b8a6">
<p>
For any of the above approaches, we would need to store data in a centralized data storage. This introduces the problem of race condition. Say two requests from a user came at the same time. We would first check the counter of user at the same time. Which will return the same value for both of the requests, (as they are read at the same time) which will allow the request to be incorrectly updated with +1 instead of +2.
</p>

<p>
A common solution to this problem is making the process atmoic. We can achieve this using lua scripts. Redis allows us to lua scripts as a mean of multi commands. Instead of putting the read<sub>counter</sub> and check<sub>and</sub><sub>update</sub> functions in the application logic, we can delegate them to redis script to read and update at the same time for each request. This would allow atomicity and handle race conditions.
</p>
</div>
</div>
</div>

<div id="outline-container-orgb25a862" class="outline-2">
<h2 id="orgb25a862">Conclusion</h2>
<div class="outline-text-2" id="text-orgb25a862">
<p>
Never thought a simple queue would have such a list of details to explain for a simple functionality. But it's interesting to see the problems arise in a distributed system. Designing such system generally pose the problems of consistency and availabity. And a rate limiter, by a simple design isn't free of it either.
</p>
</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul class="pager hidden-print">
<li class="previous">
                <a href="../am-i-back/" rel="prev" title="Am I back?">Previous post</a>
            </li>
        </ul></nav></aside></article><!--End of body content--><footer id="footer">
            Contents © 2023         <a href="mailto:mximpaid@gmail.com">Manash Baul</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
